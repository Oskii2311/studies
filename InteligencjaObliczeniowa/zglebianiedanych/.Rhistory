myFormula <-
factor(train_label) ~ gender + race.ethnicity + test.preparation.course + math.score + reading.score + writing.score
db_ctree <- ctree(myFormula, data = db.train)
tree.predicted <-
predict(db_ctree, newdata = db.test, type = "response")
tree.conf.matrix <- table(tree.predicted, test_label)
tree.accuracy <- sum(diag(tree.conf.matrix)) / sum(tree.conf.matrix)
##wykres slupkowy
barplot(
c(
tree = tree.accuracy,
Rpart2 = cart.accuracy,
knn = knn.accuracy,
nbayes = nbayes.accuracy
),
main = 'Accurancy'
)
# TPR = TP/(TP+FN)
# FPR = FP/(FP+TN)
tree.tpr <-
tree.conf.matrix[1] / (tree.conf.matrix[1] + tree.conf.matrix[3])
tree.fpr <-
tree.conf.matrix[3] / (tree.conf.matrix[3] + tree.conf.matrix[4])
knn.tpr <-
knn.conf.matrix[1] / (knn.conf.matrix[1] + knn.conf.matrix[3])
knn.fpr <-
knn.conf.matrix[3] / (knn.conf.matrix[3] + knn.conf.matrix[4])
nbayes.tpr <-
nbayes.conf.matrix[1] / (nbayes.conf.matrix[1] + nbayes.conf.matrix[3])
nbayes.fpr <-
nbayes.conf.matrix[3] / (nbayes.conf.matrix[3] + nbayes.conf.matrix[4])
rpart2.tpr <-
cart.conf.matrix[1] / (cart.conf.matrix[1] + cart.conf.matrix[3])
rpart2.fpr <-
cart.conf.matrix[3] / (cart.conf.matrix[3] + cart.conf.matrix[4])
## Wykres ROC
tprsAndFprs <- data.frame(
"CTree" = c("TPR" = tree.tpr, "FPR" = tree.fpr),
"kNN" = c("TPR" = knn.tpr, "FPR" = knn.fpr),
"NBayes" = c("TPR" = nbayes.tpr, "FPR" = nbayes.fpr),
"Rpart2" = c("TPR" = rpart2.tpr, "FPR" = rpart2.fpr)
)
rocX <- c(tree.tpr, knn.tpr, nbayes.tpr, rpart2.tpr)
rocY <- c(tree.fpr, knn.fpr, nbayes.fpr, rpart2.fpr)
names <- c("CTree", "kNN", "NBayes", "Rpart2")
plot(
rocX,
rocY,
main = "ROC",
xlab = "False Positive Rate (FPR)",
ylab = "True Positive Rate (TPR)",
col = "red",
xlim = c(0.2, 0.8),
ylim = c(0, 0.5)
)
text(rocX,
rocY,
labels = names,
cex = 0.7,
pos = c(4, 4, 2))
# Grupowanie
db.log <- log(db_normalized)
db.log <- db.log[is.finite(rowSums(db.log)),]
db.log$gender <- NULL
db.log$test.preparation.course <- NULL
db.scale <- scale(db.log, center = TRUE)
db.pca <- prcomp(db.scale)
db.final <- predict(db.pca)
db.final <- db.final[, 1:4]
db.kmeans <- kmeans(db.final, 2, nstart = 25)
table(db.kmeans[["cluster"]])
plot(db.final, col = db.kmeans[["cluster"]],
main = "k-srednich")
points(db.kmeans[["centers"]],
col = 1:2,
pch = 16,
cex = 1.5)
plot(db.final, col = as.factor(db$education), main = "k-srednich")
##asocjacje
library(arules)
raDB <- db
raDB$gender <- factor(raDB$gender)
raDB$`race/ethnicity` <- factor(raDB$`race/ethnicity`)
raDB$`test preparation course` <-
factor(raDB$`test preparation course`)
raDB$`math score` <- factor(raDB$`math score`)
raDB$`reading score` <- factor(raDB$`reading score`)
raDB$`writing score` <- factor(raDB$`writing score`)
raDB$education <- factor(raDB$education)
rules <-
apriori(raDB, parameter = list(
support = 0.3,
conf = 0.5,
target = "rules"
))
inspect(rules)
stats <- list(
"gender" = table(db$gender),
"ethnicity" = table(db$`race/ethnicity`),
"test preparation course" = table(db$`test preparation course`),
"math score" = table(db$`math score`),
"writing score" = table(db$`writing score`),
"reading score" = table(db$`reading score`),
"education" = table(db$education)
)
inspect(rules)
inspect(rules)
inspect(rules)
# zamieniamy edukacje na dwie klasy wyzsza/srednia, zeby latwiej sprawdzic czy wyzsza edukacja rodzicow ma wplyw na wyniki dzici
rpart2.accuracy
library(readr)
library(class)
library(caret)
file <- "./StudentsPerformance.csv"
db <- read_csv(file, col_names = TRUE)
uniqueEducationValues <-
unique(db$`parental level of education`, incomparables = FALSE)
# Przygotowanie bazy danych.
# zamieniamy edukacje na dwie klasy wyzsza/srednia, zeby latwiej sprawdzic czy wyzsza edukacja rodzicow ma wplyw na wyniki dzici
for (i in 1:nrow(db[3])) {
if (db[3][i, ] == uniqueEducationValues[1] ||
db[3][i, ] == uniqueEducationValues[2] ||
db[3][i, ] == uniqueEducationValues[3] ||
db[3][i, ] == uniqueEducationValues[4]) {
db[3][i, ] = "higher"
} else {
db[3][i, ] = "high"
}
}
db$gender <-
sapply(as.character(db$gender),
switch,
'male' = 0,
'female' = 1)
db$`race/ethnicity` <-
sapply(
as.character(db$`race/ethnicity`),
switch,
'group A' = 0,
'group B' = 1,
'group C' = 2,
'group D' = 3,
'group E' = 4
)
db$`test preparation course` <-
sapply(
as.character(db$`test preparation course`),
switch,
'none' = 0,
'completed' = 1
)
# usuwam kolumne  lunch, bo nie jest mi ona potrzeba do moich badan
db$`lunch` <- NULL
#zieniamy nazwe kolumny, bo uwazam, ze jest latwiejsza i krotsza
colnames(db)[which(names(db) == "parental level of education")] <-
"education"
#zmieniamy kolejnosc kolumn, tak zeby edukacja rodzicow byla na koncu
db <- db[, c(1, 2, 4, 5, 6, 7, 3)]
db <- as.data.frame(db)
# normalizacja
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num / denom)
}
db_normalized <- as.data.frame(lapply(db[1:6], normalize))
#dzielimy na zbior treningowy i testowy
set.seed(1234)
ind <-
sample(2,
nrow(db_normalized),
replace = TRUE,
prob = c(0.67, 0.33))
db.train <- db_normalized[ind == 1, 1:6]
db.test <- db_normalized[ind == 2, 1:6]
train_label <- db[ind == 1, 7]
test_label <- db[ind == 2, 7]
## rpart2
library(class)
model_rpart2 <- train(db.train, train_label, method = 'rpart2')
rpart2.predictions <- predict(object = model_rpart2, db.test)
rpart2.real <- test_label
rpart2.conf.matrix <- table(rpart2.predictions, rpart2.real)
rpart2.accuracy <-
sum(diag(rpart2.conf.matrix)) / sum(rpart2.conf.matrix)
#knn
knn.3 <- knn(db.train,
db.test,
cl = train_label,
k = 3,
prob = FALSE)
knn.predicted <- knn.3
knn.real <- test_label
knn.conf.matrix <- table(knn.predicted, knn.real)
knn.accuracy <- sum(diag(knn.conf.matrix)) / sum(knn.conf.matrix)
##bayes
library(e1071)
nbayes <- naiveBayes(db.train, as.factor(train_label))
nbayes.predicted <- predict(nbayes, db.test)
nbayes.real <- test_label
nbayes.conf.matrix <- table(nbayes.predicted, nbayes.real)
nbayes.accuracy <-
sum(diag(nbayes.conf.matrix)) / sum(nbayes.conf.matrix)
##tree
library(party)
myFormula <-
factor(train_label) ~ gender + race.ethnicity + test.preparation.course + math.score + reading.score + writing.score
db_ctree <- ctree(myFormula, data = db.train)
tree.predicted <-
predict(db_ctree, newdata = db.test, type = "response")
tree.conf.matrix <- table(tree.predicted, test_label)
tree.accuracy <- sum(diag(tree.conf.matrix)) / sum(tree.conf.matrix)
##wykres slupkowy
barplot(
c(
tree = tree.accuracy,
Rpart2 = cart.accuracy,
knn = knn.accuracy,
nbayes = nbayes.accuracy
),
main = 'Accurancy'
)
# TPR = TP/(TP+FN)
# FPR = FP/(FP+TN)
tree.tpr <-
tree.conf.matrix[1] / (tree.conf.matrix[1] + tree.conf.matrix[3])
tree.fpr <-
tree.conf.matrix[3] / (tree.conf.matrix[3] + tree.conf.matrix[4])
knn.tpr <-
knn.conf.matrix[1] / (knn.conf.matrix[1] + knn.conf.matrix[3])
knn.fpr <-
knn.conf.matrix[3] / (knn.conf.matrix[3] + knn.conf.matrix[4])
nbayes.tpr <-
nbayes.conf.matrix[1] / (nbayes.conf.matrix[1] + nbayes.conf.matrix[3])
nbayes.fpr <-
nbayes.conf.matrix[3] / (nbayes.conf.matrix[3] + nbayes.conf.matrix[4])
rpart2.tpr <-
cart.conf.matrix[1] / (cart.conf.matrix[1] + cart.conf.matrix[3])
rpart2.fpr <-
cart.conf.matrix[3] / (cart.conf.matrix[3] + cart.conf.matrix[4])
## Wykres ROC
tprsAndFprs <- data.frame(
"CTree" = c("TPR" = tree.tpr, "FPR" = tree.fpr),
"kNN" = c("TPR" = knn.tpr, "FPR" = knn.fpr),
"NBayes" = c("TPR" = nbayes.tpr, "FPR" = nbayes.fpr),
"Rpart2" = c("TPR" = rpart2.tpr, "FPR" = rpart2.fpr)
)
rocX <- c(tree.tpr, knn.tpr, nbayes.tpr, rpart2.tpr)
rocY <- c(tree.fpr, knn.fpr, nbayes.fpr, rpart2.fpr)
names <- c("CTree", "kNN", "NBayes", "Rpart2")
plot(
rocX,
rocY,
main = "ROC",
xlab = "False Positive Rate (FPR)",
ylab = "True Positive Rate (TPR)",
col = "red",
xlim = c(0.2, 0.8),
ylim = c(0, 0.5)
)
text(rocX,
rocY,
labels = names,
cex = 0.7,
pos = c(4, 4, 2))
# Grupowanie
db.log <- log(db_normalized)
db.log <- db.log[is.finite(rowSums(db.log)),]
db.log$gender <- NULL
db.log$test.preparation.course <- NULL
db.scale <- scale(db.log, center = TRUE)
db.pca <- prcomp(db.scale)
db.final <- predict(db.pca)
db.final <- db.final[, 1:4]
db.kmeans <- kmeans(db.final, 2, nstart = 25)
table(db.kmeans[["cluster"]])
plot(db.final, col = db.kmeans[["cluster"]],
main = "k-srednich")
points(db.kmeans[["centers"]],
col = 1:2,
pch = 16,
cex = 1.5)
plot(db.final, col = as.factor(db$education), main = "k-srednich")
##asocjacje
library(arules)
raDB <- db
raDB$gender <- factor(raDB$gender)
raDB$`race/ethnicity` <- factor(raDB$`race/ethnicity`)
raDB$`test preparation course` <-
factor(raDB$`test preparation course`)
raDB$`math score` <- factor(raDB$`math score`)
raDB$`reading score` <- factor(raDB$`reading score`)
raDB$`writing score` <- factor(raDB$`writing score`)
raDB$education <- factor(raDB$education)
rules <-
apriori(raDB, parameter = list(
support = 0.3,
conf = 0.5,
target = "rules"
))
inspect(rules)
stats <- list(
"gender" = table(db$gender),
"ethnicity" = table(db$`race/ethnicity`),
"test preparation course" = table(db$`test preparation course`),
"math score" = table(db$`math score`),
"writing score" = table(db$`writing score`),
"reading score" = table(db$`reading score`),
"education" = table(db$education)
)
# zamieniamy edukacje na dwie klasy wyzsza/srednia, zeby latwiej sprawdzic czy wyzsza edukacja rodzicow ma wplyw na wyniki dzici
rpart2.accuracy
library(readr)
library(class)
library(caret)
file <- "./StudentsPerformance.csv"
db <- read_csv(file, col_names = TRUE)
uniqueEducationValues <-
unique(db$`parental level of education`, incomparables = FALSE)
# Przygotowanie bazy danych.
# zamieniamy edukacje na dwie klasy wyzsza/srednia, zeby latwiej sprawdzic czy wyzsza edukacja rodzicow ma wplyw na wyniki dzici
for (i in 1:nrow(db[3])) {
if (db[3][i, ] == uniqueEducationValues[1] ||
db[3][i, ] == uniqueEducationValues[2] ||
db[3][i, ] == uniqueEducationValues[3] ||
db[3][i, ] == uniqueEducationValues[4]) {
db[3][i, ] = "higher"
} else {
db[3][i, ] = "high"
}
}
db$gender <-
sapply(as.character(db$gender),
switch,
'male' = 0,
'female' = 1)
db$`race/ethnicity` <-
sapply(
as.character(db$`race/ethnicity`),
switch,
'group A' = 0,
'group B' = 1,
'group C' = 2,
'group D' = 3,
'group E' = 4
)
db$`test preparation course` <-
sapply(
as.character(db$`test preparation course`),
switch,
'none' = 0,
'completed' = 1
)
# usuwam kolumne  lunch, bo nie jest mi ona potrzeba do moich badan
db$`lunch` <- NULL
#zieniamy nazwe kolumny, bo uwazam, ze jest latwiejsza i krotsza
colnames(db)[which(names(db) == "parental level of education")] <-
"education"
#zmieniamy kolejnosc kolumn, tak zeby edukacja rodzicow byla na koncu
db <- db[, c(1, 2, 4, 5, 6, 7, 3)]
db <- as.data.frame(db)
# normalizacja
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num / denom)
}
db_normalized <- as.data.frame(lapply(db[1:6], normalize))
#dzielimy na zbior treningowy i testowy
set.seed(1234)
ind <-
sample(2,
nrow(db_normalized),
replace = TRUE,
prob = c(0.67, 0.33))
db.train <- db_normalized[ind == 1, 1:6]
db.test <- db_normalized[ind == 2, 1:6]
train_label <- db[ind == 1, 7]
test_label <- db[ind == 2, 7]
## rpart2
library(class)
model_rpart2 <- train(db.train, train_label, method = 'rpart2')
rpart2.predictions <- predict(object = model_rpart2, db.test)
rpart2.real <- test_label
rpart2.conf.matrix <- table(rpart2.predictions, rpart2.real)
rpart2.accuracy <-
sum(diag(rpart2.conf.matrix)) / sum(rpart2.conf.matrix)
#knn
knn.3 <- knn(db.train,
db.test,
cl = train_label,
k = 3,
prob = FALSE)
knn.predicted <- knn.3
knn.real <- test_label
knn.conf.matrix <- table(knn.predicted, knn.real)
knn.accuracy <- sum(diag(knn.conf.matrix)) / sum(knn.conf.matrix)
##bayes
library(e1071)
nbayes <- naiveBayes(db.train, as.factor(train_label))
nbayes.predicted <- predict(nbayes, db.test)
nbayes.real <- test_label
nbayes.conf.matrix <- table(nbayes.predicted, nbayes.real)
nbayes.accuracy <-
sum(diag(nbayes.conf.matrix)) / sum(nbayes.conf.matrix)
##tree
library(party)
myFormula <-
factor(train_label) ~ gender + race.ethnicity + test.preparation.course + math.score + reading.score + writing.score
db_ctree <- ctree(myFormula, data = db.train)
tree.predicted <-
predict(db_ctree, newdata = db.test, type = "response")
tree.conf.matrix <- table(tree.predicted, test_label)
tree.accuracy <- sum(diag(tree.conf.matrix)) / sum(tree.conf.matrix)
##wykres slupkowy
barplot(
c(
tree = tree.accuracy,
Rpart2 = cart.accuracy,
knn = knn.accuracy,
nbayes = nbayes.accuracy
),
main = 'Accurancy'
)
# TPR = TP/(TP+FN)
# FPR = FP/(FP+TN)
tree.tpr <-
tree.conf.matrix[1] / (tree.conf.matrix[1] + tree.conf.matrix[3])
tree.fpr <-
tree.conf.matrix[3] / (tree.conf.matrix[3] + tree.conf.matrix[4])
knn.tpr <-
knn.conf.matrix[1] / (knn.conf.matrix[1] + knn.conf.matrix[3])
knn.fpr <-
knn.conf.matrix[3] / (knn.conf.matrix[3] + knn.conf.matrix[4])
nbayes.tpr <-
nbayes.conf.matrix[1] / (nbayes.conf.matrix[1] + nbayes.conf.matrix[3])
nbayes.fpr <-
nbayes.conf.matrix[3] / (nbayes.conf.matrix[3] + nbayes.conf.matrix[4])
rpart2.tpr <-
cart.conf.matrix[1] / (cart.conf.matrix[1] + cart.conf.matrix[3])
rpart2.fpr <-
cart.conf.matrix[3] / (cart.conf.matrix[3] + cart.conf.matrix[4])
## Wykres ROC
tprsAndFprs <- data.frame(
"CTree" = c("TPR" = tree.tpr, "FPR" = tree.fpr),
"kNN" = c("TPR" = knn.tpr, "FPR" = knn.fpr),
"NBayes" = c("TPR" = nbayes.tpr, "FPR" = nbayes.fpr),
"Rpart2" = c("TPR" = rpart2.tpr, "FPR" = rpart2.fpr)
)
rocX <- c(tree.tpr, knn.tpr, nbayes.tpr, rpart2.tpr)
rocY <- c(tree.fpr, knn.fpr, nbayes.fpr, rpart2.fpr)
names <- c("CTree", "kNN", "NBayes", "Rpart2")
plot(
rocX,
rocY,
main = "ROC",
xlab = "False Positive Rate (FPR)",
ylab = "True Positive Rate (TPR)",
col = "red",
xlim = c(0.2, 0.8),
ylim = c(0, 0.5)
)
text(rocX,
rocY,
labels = names,
cex = 0.7,
pos = c(4, 4, 2))
# Grupowanie
db.log <- log(db_normalized)
db.log <- db.log[is.finite(rowSums(db.log)),]
db.log$gender <- NULL
db.log$test.preparation.course <- NULL
db.scale <- scale(db.log, center = TRUE)
db.pca <- prcomp(db.scale)
db.final <- predict(db.pca)
db.final <- db.final[, 1:4]
db.kmeans <- kmeans(db.final, 2, nstart = 25)
table(db.kmeans[["cluster"]])
plot(db.final, col = db.kmeans[["cluster"]],
main = "k-srednich")
points(db.kmeans[["centers"]],
col = 1:2,
pch = 16,
cex = 1.5)
plot(db.final, col = as.factor(db$education), main = "k-srednich")
##asocjacje
library(arules)
raDB <- db
raDB$gender <- factor(raDB$gender)
raDB$`race/ethnicity` <- factor(raDB$`race/ethnicity`)
raDB$`test preparation course` <-
factor(raDB$`test preparation course`)
raDB$`math score` <- factor(raDB$`math score`)
raDB$`reading score` <- factor(raDB$`reading score`)
raDB$`writing score` <- factor(raDB$`writing score`)
raDB$education <- factor(raDB$education)
rules <-
apriori(raDB, parameter = list(
support = 0.3,
conf = 0.5,
target = "rules"
))
inspect(rules)
stats <- list(
"gender" = table(db$gender),
"ethnicity" = table(db$`race/ethnicity`),
"test preparation course" = table(db$`test preparation course`),
"math score" = table(db$`math score`),
"writing score" = table(db$`writing score`),
"reading score" = table(db$`reading score`),
"education" = table(db$education)
)
